{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WonderCat Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, base64, warnings, re\n",
    "import pandas as pd\n",
    "from qwikidata.sparql  import return_sparql_query_results\n",
    "\n",
    "import constants\n",
    "from functions import *\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call API and Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 μs, sys: 5 μs, total: 28 μs\n",
      "Wall time: 37.2 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "WordPress API Credentials and Functions\n",
    "\"\"\"\n",
    "api_prefix = 'https://env-1120817.us.reclaim.cloud/wp-json/wp/v2/user-experience'\n",
    "\n",
    "# Import credentials\n",
    "WP_USER = constants.WP_USER\n",
    "WP_KEY = constants.WP_KEY\n",
    "wp_credentials = WP_USER + WP_KEY\n",
    "wp_token = base64.b64encode(wp_credentials.encode())\n",
    "wp_header = {'Authorization': 'Basic ' + wp_token.decode('utf-8')}\n",
    "\n",
    "def get_total_pagecount():\n",
    "    api_url = f'{api_prefix}?page=1&per_page=100'\n",
    "    response = requests.get(api_url)\n",
    "    pages_count = response.headers['X-WP-TotalPages']\n",
    "    return int(pages_count)\n",
    "\n",
    "def read_wordpress_post_with_pagination():\n",
    "    total_pages = get_total_pagecount()\n",
    "    current_page = 1\n",
    "    all_page_items_json = []\n",
    "    while current_page <= total_pages:\n",
    "        api_url = f\"{api_prefix}?page={current_page}&per_page=100\"\n",
    "        page_items = requests.get(api_url)\n",
    "        page_items_json = page_items.json()\n",
    "        all_page_items_json.extend(page_items_json)\n",
    "        current_page = current_page + 1\n",
    "    return all_page_items_json\n",
    "\n",
    "\"\"\"\n",
    "Transform API JSON to Dataframe\n",
    "\"\"\"\n",
    "def transform_to_dataframe(api_call):\n",
    "    api_data = pd.DataFrame(api_call)\n",
    "    api_data = api_data[['id', 'author', 'date', 'benefit', 'experience', 'technology', 'acf']] # Select columns to work with. Add 'wikidata' when ready.\n",
    "    api_data['title'] = pd.json_normalize(api_data['acf'])['title_of_creative_work']\n",
    "    api_data['QID'] = pd.json_normalize(api_data['acf'])['wikidata-qid']\n",
    "    # This should be cleaner...\n",
    "    api_data['bene_del'] = pd.json_normalize(api_data['benefit'])\n",
    "    api_data['benefit'] = pd.json_normalize(api_data['bene_del'])['name']\n",
    "    api_data['exp_del'] = pd.json_normalize(api_data['experience'])\n",
    "    api_data['experience'] = pd.json_normalize(api_data['exp_del'])['name']\n",
    "    api_data['tech_del'] = pd.json_normalize(api_data['technology'])\n",
    "    api_data['technology'] = pd.json_normalize(api_data['tech_del'])['name']\n",
    "    del api_data['acf'], api_data['bene_del'], api_data['exp_del'], api_data['tech_del']\n",
    "\n",
    "    return api_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WikiData Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 μs, sys: 1e+03 ns, total: 5 μs\n",
      "Wall time: 7.87 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Gather all QID's from dataframe.\n",
    "def build_query_call_api(df):\n",
    "    # Gather QIDS and validate with regular expression.\n",
    "    QIDS = df['QID'].unique()\n",
    "    regex = re.compile('Q\\d+')\n",
    "    QIDS = [s for s in QIDS if regex.match(s)]\n",
    "\n",
    "    # Append 'wd:' prefix for sparql query.\n",
    "    QIDS = ' '.join(['wd:' + x for x in QIDS if isinstance(x, str)])\n",
    "\n",
    "    # Build SPARQL Query.\n",
    "    sparql_query = \"\"\"\n",
    "    SELECT DISTINCT\n",
    "        ?item ?pubDate\n",
    "        ?pubPlace ?countryOriginLabel ?coordinateLocal\n",
    "        ?genreLabel\n",
    "\n",
    "    WHERE {\n",
    "        VALUES ?item { wd:%s }\n",
    "\n",
    "        ?item wdt:P31 ?instanceof .\n",
    "        OPTIONAL {?item wdt:P136 ?genre} .\n",
    "        OPTIONAL {?item wdt:P577 ?pubDate} .\n",
    "        OPTIONAL {?item wdt:P495 ?countryOrigin} .\n",
    "    \n",
    "        SERVICE wikibase:label { bd:serviceParam wikibase:language \"en,en\". }\n",
    "    }\n",
    "    \"\"\" % (QIDS)\n",
    "\n",
    "    # Call API\n",
    "    res = return_sparql_query_results(sparql_query)\n",
    "\n",
    "    return res\n",
    "\n",
    "# Create dataframe from API results.\n",
    "def api_to_dataframe(res):\n",
    "    wiki_df =[]\n",
    "\n",
    "    # Loop through WikiQuery Results.\n",
    "    for i in res['results']['bindings']:\n",
    "        # Build empty dictionary.\n",
    "        wiki_item = {}\n",
    "        # Loop through each item's keys.\n",
    "        for k in i.keys():\n",
    "            # Append values to wiki_item\n",
    "            wiki_item[k] = i[k]['value']\n",
    "\n",
    "        # Once item's keys looped, append new dictionary to list for dataframe.\n",
    "        wiki_df.append(wiki_item)\n",
    "\n",
    "    wiki_df = pd.DataFrame(wiki_df)\n",
    "\n",
    "    # Clean up item/QID field.\n",
    "    wiki_df['item'] = wiki_df['item'].str.replace('.*/(Q\\d+)', '\\\\1', regex = True)\n",
    "    wiki_df = wiki_df.rename(columns = {'item':'QID'})\n",
    "\n",
    "    # Clean up date field. Currently returning only year due to some dates being \"out of bounds\" (too old).\n",
    "    wiki_df['pubDate'] = wiki_df['pubDate'].str.replace('(\\d{4})-\\d{2}-\\d{2}.*', '\\\\1', regex = True)\n",
    "\n",
    "    return wiki_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.45 s, sys: 470 ms, total: 6.92 s\n",
      "Wall time: 12.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>benefit</th>\n",
       "      <th>experience</th>\n",
       "      <th>technology</th>\n",
       "      <th>title</th>\n",
       "      <th>QID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>362</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-01-09T21:27:04</td>\n",
       "      <td>Faith</td>\n",
       "      <td>Wonder</td>\n",
       "      <td>Enigma</td>\n",
       "      <td>Mystery Plays</td>\n",
       "      <td>Q240911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>364</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-01-09T20:56:26</td>\n",
       "      <td>Generosity</td>\n",
       "      <td>Wonder</td>\n",
       "      <td>Stretch</td>\n",
       "      <td>Oedipus</td>\n",
       "      <td>Q148643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>363</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-01-09T20:55:14</td>\n",
       "      <td>Faith</td>\n",
       "      <td>Wonder</td>\n",
       "      <td>Plot Twist</td>\n",
       "      <td>Oedipus</td>\n",
       "      <td>Q148643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>361</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-01-09T20:51:11</td>\n",
       "      <td>Peace of Mind</td>\n",
       "      <td>Tranquility</td>\n",
       "      <td>Stream of Consciousness</td>\n",
       "      <td>Me Before You</td>\n",
       "      <td>Q20657314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-01-09T20:50:21</td>\n",
       "      <td>Peace of Mind</td>\n",
       "      <td>Tranquility</td>\n",
       "      <td>Stream of Consciousness</td>\n",
       "      <td>The Crying of Lot 49</td>\n",
       "      <td>Q2344707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  author                 date        benefit   experience  \\\n",
       "0  362       5  2025-01-09T21:27:04          Faith       Wonder   \n",
       "1  364       5  2025-01-09T20:56:26     Generosity       Wonder   \n",
       "2  363       5  2025-01-09T20:55:14          Faith       Wonder   \n",
       "3  361       5  2025-01-09T20:51:11  Peace of Mind  Tranquility   \n",
       "4  360       5  2025-01-09T20:50:21  Peace of Mind  Tranquility   \n",
       "\n",
       "                technology                 title        QID  \n",
       "0                   Enigma         Mystery Plays    Q240911  \n",
       "1                  Stretch               Oedipus    Q148643  \n",
       "2               Plot Twist               Oedipus    Q148643  \n",
       "3  Stream of Consciousness         Me Before You  Q20657314  \n",
       "4  Stream of Consciousness  The Crying of Lot 49   Q2344707  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Call Data from WordPress API\n",
    "wp_call = read_wordpress_post_with_pagination()\n",
    "\n",
    "# Reshape wp_call (json) as dataframe.\n",
    "data = transform_to_dataframe(wp_call)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.7 ms, sys: 18.1 ms, total: 64.8 ms\n",
      "Wall time: 1.74 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>benefit</th>\n",
       "      <th>experience</th>\n",
       "      <th>technology</th>\n",
       "      <th>title</th>\n",
       "      <th>QID</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>countryOriginLabel</th>\n",
       "      <th>genreLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>364</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-01-09T20:56:26</td>\n",
       "      <td>Generosity</td>\n",
       "      <td>Wonder</td>\n",
       "      <td>Stretch</td>\n",
       "      <td>Oedipus</td>\n",
       "      <td>Q148643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Greek tragedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>363</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-01-09T20:55:14</td>\n",
       "      <td>Faith</td>\n",
       "      <td>Wonder</td>\n",
       "      <td>Plot Twist</td>\n",
       "      <td>Oedipus</td>\n",
       "      <td>Q148643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Greek tragedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>361</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-01-09T20:51:11</td>\n",
       "      <td>Peace of Mind</td>\n",
       "      <td>Tranquility</td>\n",
       "      <td>Stream of Consciousness</td>\n",
       "      <td>Me Before You</td>\n",
       "      <td>Q20657314</td>\n",
       "      <td>2016</td>\n",
       "      <td>United States</td>\n",
       "      <td>romantic fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-01-09T20:50:21</td>\n",
       "      <td>Peace of Mind</td>\n",
       "      <td>Tranquility</td>\n",
       "      <td>Stream of Consciousness</td>\n",
       "      <td>The Crying of Lot 49</td>\n",
       "      <td>Q2344707</td>\n",
       "      <td>1966</td>\n",
       "      <td>United States</td>\n",
       "      <td>postmodern fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-01-09T20:50:21</td>\n",
       "      <td>Peace of Mind</td>\n",
       "      <td>Tranquility</td>\n",
       "      <td>Stream of Consciousness</td>\n",
       "      <td>The Crying of Lot 49</td>\n",
       "      <td>Q2344707</td>\n",
       "      <td>1966</td>\n",
       "      <td>United States</td>\n",
       "      <td>paranoid fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  author                 date        benefit   experience  \\\n",
       "0  364       5  2025-01-09T20:56:26     Generosity       Wonder   \n",
       "1  363       5  2025-01-09T20:55:14          Faith       Wonder   \n",
       "2  361       5  2025-01-09T20:51:11  Peace of Mind  Tranquility   \n",
       "3  360       5  2025-01-09T20:50:21  Peace of Mind  Tranquility   \n",
       "4  360       5  2025-01-09T20:50:21  Peace of Mind  Tranquility   \n",
       "\n",
       "                technology                 title        QID pubDate  \\\n",
       "0                  Stretch               Oedipus    Q148643     NaN   \n",
       "1               Plot Twist               Oedipus    Q148643     NaN   \n",
       "2  Stream of Consciousness         Me Before You  Q20657314    2016   \n",
       "3  Stream of Consciousness  The Crying of Lot 49   Q2344707    1966   \n",
       "4  Stream of Consciousness  The Crying of Lot 49   Q2344707    1966   \n",
       "\n",
       "  countryOriginLabel          genreLabel  \n",
       "0                NaN       Greek tragedy  \n",
       "1                NaN       Greek tragedy  \n",
       "2      United States    romantic fiction  \n",
       "3      United States  postmodern fiction  \n",
       "4      United States    paranoid fiction  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Call Wikidata API.\n",
    "api_results = build_query_call_api(data)\n",
    "\n",
    "# Convert API data to dataframe.\n",
    "dataframe = api_to_dataframe(api_results)\n",
    "\n",
    "# Merge with WonderCat dataframe.\n",
    "dataframe = data.merge(dataframe, how = 'inner', on = 'QID')\n",
    "\n",
    "# Save dataframe as .tsv\n",
    "dataframe.to_csv(\"../main/wonderCat_data.tsv\", sep = \"\\t\", index = False)\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data for Network Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 112 ms, sys: 10.6 ms, total: 123 ms\n",
      "Wall time: 220 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def create_nodes_and_links(dataframe):\n",
    "    # Create link/edge pairs.\n",
    "    title_tech = dataframe[['title', 'technology']]\n",
    "    title_tech.rename(columns = {'title': 'from', 'technology': 'to'}, inplace = True)\n",
    "\n",
    "    tech_exp = dataframe[['technology', 'experience']]\n",
    "    tech_exp.rename(columns = {'technology': 'from', 'experience': 'to'}, inplace = True)\n",
    "\n",
    "    exp_user = dataframe[['experience', 'author']]\n",
    "    exp_user.rename(columns = {'experience': 'from', 'author': 'to'}, inplace = True)\n",
    "\n",
    "    # Join pairs.\n",
    "    links = pd.concat([title_tech, tech_exp, exp_user]) \n",
    "\n",
    "    # Clean pairs of whitespace.\n",
    "    links['from'] = links['from'].str.replace('\\\\w', '')\n",
    "    links['to'] = links['to'].str.replace('\\\\w', '')\n",
    "\n",
    "    # Create link/edge weights.\n",
    "    links = links.groupby(['from', 'to']).size().to_frame(name = 'weight').reset_index()\n",
    "\n",
    "    # Create nodes from links and rename column name.\n",
    "    titles = dataframe[['title']]\n",
    "    titles.rename(columns = {'title': 'label'}, inplace = True)\n",
    "    titles['category'] = 'title'\n",
    "\n",
    "    technologies = dataframe[['technology']]\n",
    "    technologies.rename(columns = {'technology': 'label'}, inplace = True)\n",
    "    technologies['category'] = 'technology'\n",
    "\n",
    "    experiences = dataframe[['experience']]\n",
    "    experiences.rename(columns = {'experience': 'label'}, inplace = True)\n",
    "    experiences['category'] = 'experience'\n",
    "\n",
    "    users = dataframe[[\"author\"]]\n",
    "    users.rename(columns = {'author': 'label'}, inplace = True)\n",
    "    users['category'] = 'user'\n",
    "\n",
    "    # Concatenate nodes.\n",
    "    nodes = pd.concat([titles, technologies, experiences, users]) # users\n",
    "\n",
    "    # Create node \"size\" from frequency.\n",
    "    nodes = nodes.groupby(['label', 'category']).size().to_frame(name = 'size').reset_index()\n",
    "\n",
    "    # Remove duplicates from nodes.\n",
    "    nodes.drop_duplicates(inplace = True)\n",
    "\n",
    "    # Create node \"id's.\"\n",
    "    nodes['id'] = nodes.index\n",
    "\n",
    "    # Replace link's 'labels' with node id's.\n",
    "    label_id_map = pd.Series(nodes['id'].values, index = nodes['label']).to_dict()\n",
    "    links = links.replace({'from': label_id_map})\n",
    "    links = links.replace({'to': label_id_map})\n",
    "\n",
    "    return (links, nodes)\n",
    "\n",
    "# Create links and nodes.\n",
    "links, nodes = create_nodes_and_links(data)\n",
    "\n",
    "# Save data.\n",
    "links.to_csv(\"../main/links.tsv\", sep = \"\\t\", index = False)\n",
    "nodes.to_csv(\"../main/nodes.tsv\", sep = \"\\t\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
