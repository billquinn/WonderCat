{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WonderCat Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, base64, warnings, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call API and Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
      "Wall time: 10.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "WordPress API Credentials and Functions\n",
    "\"\"\"\n",
    "api_prefix = 'https://env-1120817.us.reclaim.cloud/wp-json/wp/v2/user-experience'\n",
    "\n",
    "def get_total_pagecount():\n",
    "    api_url = f'{api_prefix}?page=1&per_page=100'\n",
    "    response = requests.get(api_url)\n",
    "    pages_count = response.headers['X-WP-TotalPages']\n",
    "    return int(pages_count)\n",
    "\n",
    "def read_wordpress_post_with_pagination():\n",
    "    total_pages = get_total_pagecount()\n",
    "    current_page = 1\n",
    "    all_page_items_json = []\n",
    "    while current_page <= total_pages:\n",
    "        api_url = f\"{api_prefix}?page={current_page}&per_page=100\"\n",
    "        page_items = requests.get(api_url)\n",
    "        page_items_json = page_items.json()\n",
    "        all_page_items_json.extend(page_items_json)\n",
    "        current_page = current_page + 1\n",
    "    return all_page_items_json\n",
    "\n",
    "\"\"\"\n",
    "Transform API JSON to Dataframe\n",
    "\"\"\"\n",
    "def transform_to_dataframe(api_call):\n",
    "    api_data = pd.DataFrame(api_call)\n",
    "    api_data = api_data[['id', 'author', 'date', 'benefit', 'experience', 'technology', 'acf']] # Select columns to work with. Add 'wikidata' when ready.\n",
    "    api_data['title'] = pd.json_normalize(api_data['acf'])['title_of_creative_work']\n",
    "    api_data['QID'] = pd.json_normalize(api_data['acf'])['wikidata-qid']\n",
    "    # This should be cleaner...\n",
    "    api_data['bene_del'] = pd.json_normalize(api_data['benefit'])\n",
    "    api_data['benefit'] = pd.json_normalize(api_data['bene_del'])['name']\n",
    "    api_data['exp_del'] = pd.json_normalize(api_data['experience'])\n",
    "    api_data['experience'] = pd.json_normalize(api_data['exp_del'])['name']\n",
    "    api_data['tech_del'] = pd.json_normalize(api_data['technology'])\n",
    "    api_data['technology'] = pd.json_normalize(api_data['tech_del'])['name']\n",
    "    del api_data['acf'], api_data['bene_del'], api_data['exp_del'], api_data['tech_del']\n",
    "\n",
    "    # Convert date of experience to Y-m-d\n",
    "    api_data['date'] = api_data['date'].str.replace('(\\d{4}-\\d{2}-\\d{2}).*', '\\\\1', regex = True)\n",
    "    api_data['date'] = pd.to_datetime(api_data['date'])\n",
    "\n",
    "\n",
    "    return api_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write WonderCat API Results to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.75 s, sys: 364 ms, total: 2.12 s\n",
      "Wall time: 10.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>benefit</th>\n",
       "      <th>experience</th>\n",
       "      <th>technology</th>\n",
       "      <th>title</th>\n",
       "      <th>QID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>848</td>\n",
       "      <td>6</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>Creativity</td>\n",
       "      <td>Wonder</td>\n",
       "      <td>Poetic Language</td>\n",
       "      <td>A Room of One's Own by Virginia Woolf</td>\n",
       "      <td>Q1204366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>847</td>\n",
       "      <td>6</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>Creative Breakthrough</td>\n",
       "      <td>Relearning</td>\n",
       "      <td>Poetic History</td>\n",
       "      <td>A Room of One's Own</td>\n",
       "      <td>Q1204366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>846</td>\n",
       "      <td>6</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>Connection</td>\n",
       "      <td>Superiority</td>\n",
       "      <td>Insinuation</td>\n",
       "      <td>A Room of One's Own</td>\n",
       "      <td>Q1204366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>845</td>\n",
       "      <td>6</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>Resilience</td>\n",
       "      <td>Identification</td>\n",
       "      <td>Soliloquy</td>\n",
       "      <td>A Room of One's Own</td>\n",
       "      <td>Q1204366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>777</td>\n",
       "      <td>6</td>\n",
       "      <td>2025-03-11</td>\n",
       "      <td>Gratitude</td>\n",
       "      <td>Identification</td>\n",
       "      <td>Stream of Consciousness</td>\n",
       "      <td>To the Lighthouse</td>\n",
       "      <td>Q478016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  author       date                benefit      experience  \\\n",
       "0  848       6 2025-04-16             Creativity          Wonder   \n",
       "1  847       6 2025-04-16  Creative Breakthrough      Relearning   \n",
       "2  846       6 2025-04-16             Connection     Superiority   \n",
       "3  845       6 2025-04-16             Resilience  Identification   \n",
       "4  777       6 2025-03-11              Gratitude  Identification   \n",
       "\n",
       "                technology                                  title       QID  \n",
       "0          Poetic Language  A Room of One's Own by Virginia Woolf  Q1204366  \n",
       "1           Poetic History                    A Room of One's Own  Q1204366  \n",
       "2              Insinuation                    A Room of One's Own  Q1204366  \n",
       "3                Soliloquy                    A Room of One's Own  Q1204366  \n",
       "4  Stream of Consciousness                      To the Lighthouse   Q478016  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Call Data from WordPress API\n",
    "wp_call = read_wordpress_post_with_pagination()\n",
    "\n",
    "# Reshape wp_call (json) as dataframe.\n",
    "data = transform_to_dataframe(wp_call)\n",
    "\n",
    "# Write to file.\n",
    "data.to_csv(\"wonderCat_data.tsv\", sep = \"\\t\", index = False)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WikiData Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 1 µs, total: 7 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Gather all QID's from dataframe.\n",
    "def get_QIDS(df):\n",
    "    # Gather QIDS and validate with regular expression.\n",
    "    QIDS = df['QID'].unique()\n",
    "    regex = re.compile('Q\\d+')\n",
    "    QIDS = [s for s in QIDS if regex.match(s)]\n",
    "\n",
    "    # Append 'wd:' prefix for sparql query.\n",
    "    QIDS = ' '.join(['wd:' + x for x in QIDS if isinstance(x, str)])\n",
    "\n",
    "    return QIDS\n",
    "\n",
    "\n",
    "# Build SPARQL query.\n",
    "def build_query_call_api(QIDS):\n",
    "    QIDS = QIDS\n",
    "\n",
    "    # Build SPARQL Query.\n",
    "    sparql_query = \"\"\"\n",
    "    SELECT DISTINCT\n",
    "        ?item ?pubDate ?genreLabel\n",
    "        ?countryOriginLabel ?coordinates\n",
    "\n",
    "    WHERE {\n",
    "        VALUES ?item { %s }\n",
    "\n",
    "        ?item wdt:P31 ?instanceof.\n",
    "        OPTIONAL {?item wdt:P136 ?genre}.\n",
    "        OPTIONAL {?item wdt:P577 ?pubDate}.\n",
    "        ?item wdt:P495 ?countryOrigin .\n",
    "        ?countryOrigin wdt:P625 ?coordinates.\n",
    "    \n",
    "        SERVICE wikibase:label { bd:serviceParam wikibase:language \"en,en\". }\n",
    "    }\n",
    "    \"\"\" % (QIDS)\n",
    "\n",
    "    # Call API\n",
    "    url = 'https://query.wikidata.org/bigdata/namespace/wdq/sparql'\n",
    "    res = requests.get(url, params={'query': sparql_query, 'format': 'json'}).json()\n",
    "\n",
    "    return res\n",
    "\n",
    "# Create dataframe from API results.\n",
    "def api_to_dataframe(res):\n",
    "    wiki_df =[]\n",
    "\n",
    "    # Loop through WikiQuery Results.\n",
    "    for i in res['results']['bindings']:\n",
    "        # Build empty dictionary.\n",
    "        wiki_item = {}\n",
    "        # Loop through each item's keys.\n",
    "        for k in i.keys():\n",
    "            # Append values to wiki_item\n",
    "            wiki_item[k] = i[k]['value']\n",
    "\n",
    "        # Once item's keys looped, append new dictionary to list for dataframe.\n",
    "        wiki_df.append(wiki_item)\n",
    "\n",
    "    wiki_df = pd.DataFrame(wiki_df)\n",
    "\n",
    "    # Clean up item/QID field.\n",
    "    wiki_df['item'] = wiki_df['item'].str.replace('.*/(Q\\d+)', '\\\\1', regex = True)\n",
    "    wiki_df = wiki_df.rename(columns = {'item':'QID'})\n",
    "\n",
    "    # Clean up date field. Currently returning only year due to some dates being \"out of bounds\" (too old).\n",
    "    wiki_df['pubDate'] = wiki_df['pubDate'].str.replace('(\\d{4}-\\d{2}-\\d{2}).*', '\\\\1', regex = True)\n",
    "    wiki_df['pubDate'] = pd.to_datetime(wiki_df['pubDate'], errors = 'coerce')\n",
    "\n",
    "    # Create Longitude and Latitude columns.\n",
    "    reg_pattern = 'Point\\(([-]?\\d+\\.?\\d+)\\s([-]?\\d+\\.?\\d+)\\)'\n",
    "    wiki_df['long'] = wiki_df['coordinates'].str.replace(reg_pattern, '\\\\1', regex = True)\n",
    "    wiki_df['lat'] = wiki_df['coordinates'].str.replace(reg_pattern, '\\\\2', regex = True)\n",
    "\n",
    "    # # Convert rows of genres into single value (list)\n",
    "    # wiki_df = wiki_df.groupby(['QID', 'long', 'lat'], as_index=False) \\\n",
    "    #     .agg({'genreLabel': lambda x: x.tolist(), 'pubDate': lambda x: x.tolist()})\n",
    "\n",
    "    return wiki_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QID                   False\n",
      "title                 False\n",
      "coordinates           False\n",
      "genreLabel            False\n",
      "countryOriginLabel    False\n",
      "pubDate               False\n",
      "long                  False\n",
      "lat                   False\n",
      "dtype: bool\n",
      "CPU times: user 33.9 ms, sys: 5.24 ms, total: 39.1 ms\n",
      "Wall time: 424 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>title</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>genreLabel</th>\n",
       "      <th>countryOriginLabel</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1204366</td>\n",
       "      <td>A Room of One's Own by Virginia Woolf</td>\n",
       "      <td>Point(-1.0 53.0)</td>\n",
       "      <td>essay</td>\n",
       "      <td>England</td>\n",
       "      <td>1929-09-01</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1204366</td>\n",
       "      <td>A Room of One's Own</td>\n",
       "      <td>Point(-1.0 53.0)</td>\n",
       "      <td>essay</td>\n",
       "      <td>England</td>\n",
       "      <td>1929-09-01</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1204366</td>\n",
       "      <td>A Room of One's Own</td>\n",
       "      <td>Point(-1.0 53.0)</td>\n",
       "      <td>essay</td>\n",
       "      <td>England</td>\n",
       "      <td>1929-09-01</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1204366</td>\n",
       "      <td>A Room of One's Own</td>\n",
       "      <td>Point(-1.0 53.0)</td>\n",
       "      <td>essay</td>\n",
       "      <td>England</td>\n",
       "      <td>1929-09-01</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q478016</td>\n",
       "      <td>To the Lighthouse</td>\n",
       "      <td>Point(-2.0 54.6)</td>\n",
       "      <td>modernist literature</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1927-01-01</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>54.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        QID                                  title       coordinates  \\\n",
       "0  Q1204366  A Room of One's Own by Virginia Woolf  Point(-1.0 53.0)   \n",
       "1  Q1204366                    A Room of One's Own  Point(-1.0 53.0)   \n",
       "2  Q1204366                    A Room of One's Own  Point(-1.0 53.0)   \n",
       "3  Q1204366                    A Room of One's Own  Point(-1.0 53.0)   \n",
       "4   Q478016                      To the Lighthouse  Point(-2.0 54.6)   \n",
       "\n",
       "             genreLabel countryOriginLabel    pubDate  long   lat  \n",
       "0                 essay            England 1929-09-01  -1.0  53.0  \n",
       "1                 essay            England 1929-09-01  -1.0  53.0  \n",
       "2                 essay            England 1929-09-01  -1.0  53.0  \n",
       "3                 essay            England 1929-09-01  -1.0  53.0  \n",
       "4  modernist literature     United Kingdom 1927-01-01  -2.0  54.6  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Get QIDS.\n",
    "qids = get_QIDS(data)\n",
    "\n",
    "# Call Wikidata API.\n",
    "api_results = build_query_call_api(qids)\n",
    "\n",
    "# Convert API data to dataframe.\n",
    "wikidata = api_to_dataframe(api_results)\n",
    "\n",
    "# Merge with WonderCat dataframe.\n",
    "wikidata = data[['QID', 'title']].merge(wikidata, how = 'inner', on = 'QID')\n",
    "\n",
    "# Save dataframe as .tsv\n",
    "wikidata.to_csv(\"wikidata.tsv\", sep = \"\\t\", index = False)\n",
    "\n",
    "# See if columns that have lists are recognized.\n",
    "print (wikidata.map(lambda x: isinstance(x, list)).all())\n",
    "\n",
    "wikidata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Network Data with Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def create_nodes_and_links(dataframe, column1, column2):\n",
    "    # Create link/edge pairs.\n",
    "    title_tech = dataframe[['title', 'technology']]\n",
    "    title_tech.rename(columns = {'title': 'from', 'technology': 'to'}, inplace = True)\n",
    "\n",
    "    # Clean pairs of whitespace.\n",
    "    links['from'] = links['from'].str.replace('\\\\w', '')\n",
    "    links['to'] = links['to'].str.replace('\\\\w', '')\n",
    "\n",
    "    # Create link/edge weights.\n",
    "    links = links.groupby(['from', 'to']).size().to_frame(name = 'weight').reset_index()\n",
    "\n",
    "    # Create nodes from links and rename column name.\n",
    "    titles = dataframe[['title']]\n",
    "    titles.rename(columns = {'title': 'label'}, inplace = True)\n",
    "    titles['category'] = 'title'\n",
    "\n",
    "    technologies = dataframe[['technology']]\n",
    "    technologies.rename(columns = {'technology': 'label'}, inplace = True)\n",
    "    technologies['category'] = 'technology'\n",
    "\n",
    "    experiences = dataframe[['experience']]\n",
    "    experiences.rename(columns = {'experience': 'label'}, inplace = True)\n",
    "    experiences['category'] = 'experience'\n",
    "\n",
    "    users = dataframe[[\"author\"]]\n",
    "    users.rename(columns = {'author': 'label'}, inplace = True)\n",
    "    users['category'] = 'user'\n",
    "\n",
    "    # Concatenate nodes.\n",
    "    nodes = pd.concat([titles, technologies, experiences, users]) # users\n",
    "\n",
    "    # Create node \"size\" from frequency.\n",
    "    nodes = nodes.groupby(['label', 'category']).size().to_frame(name = 'size').reset_index()\n",
    "\n",
    "    # Remove duplicates from nodes.\n",
    "    nodes.drop_duplicates(inplace = True)\n",
    "\n",
    "    # Create node \"id's.\"\n",
    "    nodes['id'] = nodes.index\n",
    "\n",
    "    # Replace link's 'labels' with node id's.\n",
    "    label_id_map = pd.Series(nodes['id'].values, index = nodes['label']).to_dict()\n",
    "    links = links.replace({'from': label_id_map})\n",
    "    links = links.replace({'to': label_id_map})\n",
    "\n",
    "    return (links, nodes)\n",
    "\n",
    "# Create links and nodes.\n",
    "links, nodes = create_nodes_and_links(data)\n",
    "\n",
    "# Save data.\n",
    "links.to_csv(\"../main/links.tsv\", sep = \"\\t\", index = False)\n",
    "nodes.to_csv(\"../main/nodes.tsv\", sep = \"\\t\", index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data for Network Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 123 ms, sys: 6.92 ms, total: 130 ms\n",
      "Wall time: 158 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def create_nodes_and_links(dataframe):\n",
    "    # Create link/edge pairs.\n",
    "    title_tech = dataframe[['title', 'technology']]\n",
    "    title_tech.rename(columns = {'title': 'from', 'technology': 'to'}, inplace = True)\n",
    "\n",
    "    tech_exp = dataframe[['technology', 'experience']]\n",
    "    tech_exp.rename(columns = {'technology': 'from', 'experience': 'to'}, inplace = True)\n",
    "\n",
    "    exp_user = dataframe[['experience', 'author']]\n",
    "    exp_user.rename(columns = {'experience': 'from', 'author': 'to'}, inplace = True)\n",
    "\n",
    "    # Join pairs.\n",
    "    links = pd.concat([title_tech, tech_exp, exp_user]) \n",
    "\n",
    "    # Clean pairs of whitespace.\n",
    "    links['from'] = links['from'].str.replace('\\\\w', '')\n",
    "    links['to'] = links['to'].str.replace('\\\\w', '')\n",
    "\n",
    "    # Create link/edge weights.\n",
    "    links = links.groupby(['from', 'to']).size().to_frame(name = 'weight').reset_index()\n",
    "\n",
    "    # Create nodes from links and rename column name.\n",
    "    titles = dataframe[['title']]\n",
    "    titles.rename(columns = {'title': 'label'}, inplace = True)\n",
    "    titles['category'] = 'title'\n",
    "\n",
    "    technologies = dataframe[['technology']]\n",
    "    technologies.rename(columns = {'technology': 'label'}, inplace = True)\n",
    "    technologies['category'] = 'technology'\n",
    "\n",
    "    experiences = dataframe[['experience']]\n",
    "    experiences.rename(columns = {'experience': 'label'}, inplace = True)\n",
    "    experiences['category'] = 'experience'\n",
    "\n",
    "    users = dataframe[[\"author\"]]\n",
    "    users.rename(columns = {'author': 'label'}, inplace = True)\n",
    "    users['category'] = 'user'\n",
    "\n",
    "    # Concatenate nodes.\n",
    "    nodes = pd.concat([titles, technologies, experiences, users]) # users\n",
    "\n",
    "    # Create node \"size\" from frequency.\n",
    "    nodes = nodes.groupby(['label', 'category']).size().to_frame(name = 'size').reset_index()\n",
    "\n",
    "    # Remove duplicates from nodes.\n",
    "    nodes.drop_duplicates(inplace = True)\n",
    "\n",
    "    # Create node \"id's.\"\n",
    "    nodes['id'] = nodes.index\n",
    "\n",
    "    # Replace link's 'labels' with node id's.\n",
    "    label_id_map = pd.Series(nodes['id'].values, index = nodes['label']).to_dict()\n",
    "    links = links.replace({'from': label_id_map})\n",
    "    links = links.replace({'to': label_id_map})\n",
    "\n",
    "    return (links, nodes)\n",
    "\n",
    "# Create links and nodes.\n",
    "links, nodes = create_nodes_and_links(data)\n",
    "\n",
    "# Save data.\n",
    "links.to_csv(\"../main/links.tsv\", sep = \"\\t\", index = False)\n",
    "nodes.to_csv(\"../main/nodes.tsv\", sep = \"\\t\", index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
